{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# <font style=\"color:blue\">Assignment: Implement a CNN for Image Classification on CIFAR10 dataset</font>\n",
    "\n",
    "We have seen how to implement a CNN (LeNet5 and LeNet with the batch norm) in the last section. We used MNIST and Fashion MNIST dataset which are grayscale or single channel datasets. In this assignment, you will implement a CNN Model ( similar to LeNet ) for classifying objects in the `CIFAR10` dataset. \n",
    "\n",
    "The CIFAR10 dataset has the following properties\n",
    "1. It has `10` classes.  \n",
    "1. It has colored images, so it has `3-channels`. \n",
    "1. The image shape is `32 x 32`.\n",
    "\n",
    "Samples of CIFAR10- dataset ([source](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html?highlight=cifar)):\n",
    "\n",
    "<img src=\"https://www.learnopencv.com/wp-content/uploads/2020/01/c3_w3_cirar10.png\" width=700>\n",
    "\n",
    "\n",
    "# <font color='blue'>Marking Scheme</font>\n",
    "\n",
    "### <font style=\"color:green\">Maximum Points: 30\n",
    "\n",
    "<div>\n",
    "    <table>\n",
    "        <tr><td><h3>Sr. no.</h3></td> <td><h3>Problem</h3></td> <td><h3>Points</h3></td> </tr>\n",
    "        <tr><td><h3>1</h3></td> <td><h3>Implement the CNN Model</h3></td> <td><h3>10</h3></td> </tr>\n",
    "        <tr><td><h3>2</h3></td> <td><h3>Find Mean and Std of Training Data</h3></td> <td><h3>5</h3></td> </tr>\n",
    "        <tr><td><h3>3</h3></td> <td><h3>Model Training & Accuracy</h3></td> <td><h3>15</h3></td> </tr>\n",
    "    </table>\n",
    "</div>\n",
    "\n",
    "\n",
    "# <font color='blue'>Problem Description</font>\n",
    "\n",
    "### <font color='blue'>1. Implement the CNN Model</font>\n",
    "Since the task is to classify objects in a dataset of color images, you need to implement a CNN with 10 output classes. **Also, your model must use `Conv2d`, `BatchNorm2d`, and `ReLU`.** \n",
    "\n",
    "**You need to define the model architecture in the function: `MyModel` ( Step 1 )**\n",
    "\n",
    "Hint: For color images you need to use an input shape that is different than the ones we have been using till now, so that it accepts 3 channel inputs.\n",
    "\n",
    "### <font color='blue'>2. Find Mean and Std of Training Data</font>\n",
    "\n",
    "It is a good practice to normalize the training data. To normalize the data, we need to compute mean and std. As the dataset has colored images, it has `3-channel` (RGB or BGR). We have to find mean and std per channel using training data. \n",
    "\n",
    "**You need to compute the mean and std for the dataset in the function: `get_mean_std_train_data` ( Step 3 )**\n",
    "\n",
    "### <font color='blue'>3. Model Training and Accuracy</font>\n",
    "\n",
    "Once you have defined the model, you can train it. To get better accuracy, you need to play around the training configuration **( Step 5 )** and even the model architecture. You can check the accuracy by running the training loop in `Step 11`.\n",
    "\n",
    "Here are a few hints on how you can improve the accuracy:\n",
    "- Train for longer duration\n",
    "- Try with different learning rate\n",
    "- Try to add more convolutional layers to the architecture\n",
    "- Try to add more nodes in the layers.\n",
    "\n",
    "You need to achieve **75% accuracy** ( See Step11 ) in order to get full marks for this part. \n",
    "\n",
    "**You do not need to implement anything for this, just changing the parameters as mentioned above and running the Notebook will give you the accuracy. ( Step 5 and Step 11 )**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Note that this notebook requires you to change a few stuff in the model to get the desired accuracy. Therefore you need train the model all over again (which seems to be time-consuming).   \n",
    "\n",
    "You can choose to execute this notebook in Google-Colab so that you have access to a GPU-machine and prototype faster.   \n",
    "\n",
    "Once the desired results are acheived, you can copy-paste the changes made in the Colab-notebook to this notebook so that the grading occurs on the latest code. \n",
    "\n",
    "You can access the Colab-notebook from [here](https://colab.research.google.com/drive/18lgSRmHPagJkB0xmDq5ZiWGkuWcHnUc2?usp=sharing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "required_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt  # one of the best graphics library for python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "from typing import Iterable\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font style=\"color:blue\">1. CNN Model Architecture [10 Points]</font>\n",
    "\n",
    "You have to write the model code here. You can take reference from LeNet code.\n",
    "\n",
    "If you do not get higher accuracy, here are a few hints:\n",
    "- Try to add more convolutional layers to the architecture\n",
    "- Try to add more nodes in the layers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # convolution layers\n",
    "        self._body = nn.Sequential(\n",
    "            # First convolution Layer\n",
    "            # input size = (32, 32), output size = (32, 32)\n",
    "            # Input N, Cin, Hin, Win; here N = batch size, Cin = 1\n",
    "            # Output N, Cout, Hout, Wout; here Cout = 32 and Hout = floor((Hin + 2*padding - kernel[0])/stride) + 1\n",
    "            # here stride = 1, padding = 1; hence Hout = 32\n",
    "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
    "            # ReLU activation\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            # Max pool 2-d, stride's default is same as kernel size\n",
    "            # Input  N, C, Hin, Win; here N = batch size, C = # of channels\n",
    "            # Output N, C, Hout, Wout; here Hout = floor((Hin + 2*padding - kernel[0])/stride) + 1\n",
    "            # Here stride = 2, padding = 0; hence Hout = ((32 - 2)/2) + 1 = 16\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            \n",
    "            # Second convolution layer\n",
    "            # input size = (16, 16), output size = (16, 16)\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            # output size = (8, 8)\n",
    "            #nn.Dropout2d(p=0.05),\n",
    "            \n",
    "            # Third convolution layer\n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            # output size = (4, 4)\n",
    "        )\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self._head = nn.Sequential(\n",
    "            #nn.Dropout(p=0.1),\n",
    "            # First fully connected layer\n",
    "            # in_features = total number of weights in last conv layer = 16 * 5 * 5\n",
    "            nn.Linear(in_features=4096, out_features=1024), \n",
    "\n",
    "            # ReLU activation\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            # second fully connected layer\n",
    "            # in_features = output of last linear layer = 120 \n",
    "            nn.Linear(in_features=1024, out_features=512), \n",
    "            \n",
    "            # ReLU activation\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            # Third fully connected layer. It is also the output layer\n",
    "            # in_features = output of last linear layer = 84\n",
    "            # and out_features = number of classes = 10 (MNIST data 0-9)\n",
    "            #nn.Dropout(p=0.1),\n",
    "            nn.Linear(in_features=512, out_features=10)\n",
    "        )\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # apply feature extractor\n",
    "        x = self._body(x)\n",
    "        # flatten the output of conv layers\n",
    "        # dimension should be batch_size * number_of weights_in_last conv_layer\n",
    "        x = x.view(x.size()[0], -1)\n",
    "        # apply classification head\n",
    "        x = self._head(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# <font style=\"color:blue\">2. Display the Network</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyModel(\n",
      "  (_body): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): ReLU(inplace=True)\n",
      "    (8): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (12): ReLU(inplace=True)\n",
      "    (13): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (_head): Sequential(\n",
      "    (0): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "my_model = MyModel()\n",
    "print(my_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Conv2d",
     "locked": true,
     "points": "3",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "BatchNorm2d",
     "locked": true,
     "points": "2",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "ReLU",
     "locked": true,
     "points": "2",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "input-output",
     "locked": true,
     "points": "3",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "lines_to_next_cell": 2,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# <font style=\"color:blue\">3. Find Mean and STD of CIFAR10 Data [5 Points]</font>\n",
    "\n",
    "Function **`get_mean_std_train_data`** should `return` `mean` and `std` of training data. You can refer to the code used in the previous section for finding the mean and std of the training data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": false,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def get_mean_std_train_data(data_root):\n",
    "    \n",
    "    train_transform = transforms.Compose([transforms.ToTensor()])\n",
    "    train_set = datasets.CIFAR10(root=data_root, train=True, download=False, transform=train_transform)\n",
    "    \n",
    "    # return mean (numpy.ndarray) and std (numpy.ndarray)\n",
    "    mean = np.array([0.5, 0.5, 0.5])\n",
    "    std = np.array([0.5, 0.5, 0.5])\n",
    "    \n",
    "    for i in range(train_set.data.shape[3]):\n",
    "        mean[i] = train_set.data[:,:,:,i].mean()/255\n",
    "        std[i] = train_set.data[:,:,:,i].std()/255\n",
    "   \n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "lines_to_next_cell": 2,
    "nbgrader": {
     "grade": true,
     "grade_id": "mean",
     "locked": true,
     "points": "2",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "lines_to_next_cell": 2,
    "nbgrader": {
     "grade": true,
     "grade_id": "std",
     "locked": true,
     "points": "3",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# <font style=\"color:blue\">4. System Configuration</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def get_data(batch_size, data_root, num_workers=1):\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        mean, std = get_mean_std_train_data(data_root)\n",
    "        assert len(mean) == len(std) == 3\n",
    "    except:\n",
    "        mean = np.array([0.5, 0.5, 0.5])\n",
    "        std = np.array([0.5, 0.5, 0.5])\n",
    "        \n",
    "    \n",
    "    train_test_transforms = transforms.Compose([\n",
    "        # this re-scale image tensor values between 0-1. image_tensor /= 255\n",
    "        transforms.ToTensor(),\n",
    "        # subtract mean and divide by variance.\n",
    "        transforms.Normalize(mean, std)\n",
    "    ])\n",
    "    \n",
    "    # train dataloader\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        datasets.CIFAR10(root=data_root, train=True, download=False, transform=train_test_transforms),\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers\n",
    "    )\n",
    "    \n",
    "    # test dataloader\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        datasets.CIFAR10(root=data_root, train=False, download=False, transform=train_test_transforms),\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers\n",
    "    )\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class SystemConfiguration:\n",
    "    '''\n",
    "    Describes the common system setting needed for reproducible training\n",
    "    '''\n",
    "    seed: int = 42  # seed number to set the state of all random number generators\n",
    "    cudnn_benchmark_enabled: bool = True  # enable CuDNN benchmark for the sake of performance\n",
    "    cudnn_deterministic: bool = True  # make cudnn deterministic (reproducible training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# <font style=\"color:blue\">5. Training Configuration [15 Points]</font>\n",
    "All training parameters are defined here. So, \n",
    "This is where you can improve your accuracy, apart from improving the architecture. \n",
    "\n",
    "Here are a few hints on how you can improve the accuracy:\n",
    "- Train for longer duration\n",
    "- Try with different learning rate\n",
    "\n",
    "**You need to achieve 75% accuracy in order to get full marks for this part.**\n",
    "\n",
    "**You will see the effect of these changes when you run Step 11**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "locked": false,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class TrainingConfiguration:\n",
    "    '''\n",
    "    Describes configuration of the training process\n",
    "    '''\n",
    "    batch_size: int = 16  # amount of data to pass through the network at each forward-backward iteration\n",
    "    epochs_count: int = 2  # number of times the whole dataset will be passed through the network\n",
    "    learning_rate: float = 0.1  # determines the speed of network's weights update\n",
    "        \n",
    "    log_interval: int = 100  # how many batches to wait between logging training status\n",
    "    test_interval: int = 1  # how many epochs to wait before another test. Set to 1 to get val loss at each epoch\n",
    "    data_root: str = \"../resource/lib/publicdata/images\"  # folder to save data\n",
    "    num_workers: int = 10  # number of concurrent processes using to prepare data\n",
    "    device: str = 'cuda'  # device to use for training.\n",
    "    # update changed parameters in blow coding block.\n",
    "    # Please do not change \"data_root\" \n",
    "    \n",
    "    learning_rate = 0.01\n",
    "    epochs_count = 5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# <font style=\"color:blue\">6. System Setup</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def setup_system(system_config: SystemConfiguration) -> None:\n",
    "    torch.manual_seed(system_config.seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.backends.cudnn_benchmark_enabled = system_config.cudnn_benchmark_enabled\n",
    "        torch.backends.cudnn.deterministic = system_config.cudnn_deterministic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# <font style=\"color:blue\">7. Training</font>\n",
    "We are familiar with the training pipeline used in PyTorch. The following steps are performed in the code below:\n",
    "\n",
    "1. Send the data to the required device ( CPU/GPU )\n",
    "1. Make a forward pass using the forward method.\n",
    "1. Find the loss using the Cross_Entropy function.\n",
    "1. Find the gradients using the backward function.\n",
    "1. Update the weights using the optimizer.\n",
    "1. Find the accuracy of the model\n",
    "\n",
    "Repeat the above for the specified number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def train(\n",
    "    train_config: TrainingConfiguration, model: nn.Module, optimizer: torch.optim.Optimizer,\n",
    "    train_loader: torch.utils.data.DataLoader, epoch_idx: int\n",
    ") -> None:\n",
    "    \n",
    "    # change model in training mood\n",
    "    model.train()\n",
    "    \n",
    "    # to get batch loss\n",
    "    batch_loss = np.array([])\n",
    "    \n",
    "    # to get batch accuracy\n",
    "    batch_acc = np.array([])\n",
    "        \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        \n",
    "        # clone target\n",
    "        indx_target = target.clone()\n",
    "        # send data to device (its is medatory if GPU has to be used)\n",
    "        data = data.to(train_config.device)\n",
    "        # send target to device\n",
    "        target = target.to(train_config.device)\n",
    "\n",
    "        # reset parameters gradient to zero\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward pass to the model\n",
    "        output = model(data)\n",
    "        \n",
    "        # cross entropy loss\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        \n",
    "        # find gradients w.r.t training parameters\n",
    "        loss.backward()\n",
    "        # Update parameters using gardients\n",
    "        optimizer.step()\n",
    "        \n",
    "        batch_loss = np.append(batch_loss, [loss.item()])\n",
    "        \n",
    "        # Score to probability using softmax\n",
    "        prob = F.softmax(output, dim=1)\n",
    "            \n",
    "        # get the index of the max probability\n",
    "        pred = prob.data.max(dim=1)[1]  \n",
    "                        \n",
    "        # correct prediction\n",
    "        correct = pred.cpu().eq(indx_target).sum()\n",
    "            \n",
    "        # accuracy\n",
    "        acc = float(correct) / float(len(data))\n",
    "        \n",
    "        batch_acc = np.append(batch_acc, [acc])\n",
    "\n",
    "        if batch_idx % train_config.log_interval == 0 and batch_idx > 0:              \n",
    "            print(\n",
    "                'Train Epoch: {} [{}/{}] Loss: {:.6f} Acc: {:.4f}'.format(\n",
    "                    epoch_idx, batch_idx * len(data), len(train_loader.dataset), loss.item(), acc\n",
    "                )\n",
    "            )\n",
    "            \n",
    "    epoch_loss = batch_loss.mean()\n",
    "    epoch_acc = batch_acc.mean()\n",
    "    return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# <font style=\"color:blue\">8. Validation</font>\n",
    "\n",
    "After every few epochs **`validation`** will be called with the `trained model` and `test_loader` to get validation loss and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def validate(\n",
    "    train_config: TrainingConfiguration,\n",
    "    model: nn.Module,\n",
    "    test_loader: torch.utils.data.DataLoader,\n",
    ") -> float:\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    count_corect_predictions = 0\n",
    "    for data, target in test_loader:\n",
    "        indx_target = target.clone()\n",
    "        data = data.to(train_config.device)\n",
    "        \n",
    "        target = target.to(train_config.device)\n",
    "        \n",
    "        output = model(data)\n",
    "        # add loss for each mini batch\n",
    "        test_loss += F.cross_entropy(output, target).item()\n",
    "        \n",
    "        # Score to probability using softmax\n",
    "        prob = F.softmax(output, dim=1)\n",
    "        \n",
    "        # get the index of the max probability\n",
    "        pred = prob.data.max(dim=1)[1] \n",
    "        \n",
    "        # add correct prediction count\n",
    "        count_corect_predictions += pred.cpu().eq(indx_target).sum()\n",
    "\n",
    "    # average over number of mini-batches\n",
    "    test_loss = test_loss / len(test_loader)  \n",
    "    \n",
    "    # average over number of dataset\n",
    "    accuracy = 100. * count_corect_predictions / len(test_loader.dataset)\n",
    "    \n",
    "    print(\n",
    "        '\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "            test_loss, count_corect_predictions, len(test_loader.dataset), accuracy\n",
    "        )\n",
    "    )\n",
    "    return test_loss, accuracy/100.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# <font style=\"color:blue\">9. Saving the Model</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def save_model(model, device, model_dir='models', model_file_name='cifar10_cnn_model.pt'):\n",
    "    \n",
    "\n",
    "    if not os.path.exists(model_dir):\n",
    "        os.makedirs(model_dir)\n",
    "\n",
    "    model_path = os.path.join(model_dir, model_file_name)\n",
    "\n",
    "    # make sure you transfer the model to cpu.\n",
    "    if device == 'cuda':\n",
    "        model.to('cpu')\n",
    "\n",
    "    # save the state_dict\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    \n",
    "    if device == 'cuda':\n",
    "        model.to('cuda')\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# <font style=\"color:blue\">10. Main</font>\n",
    "\n",
    "In this section of code, we use the configuration parameters defined above and start the training. Here are the important actions being taken in the code below:\n",
    "\n",
    "1. Set up system parameters like CPU/GPU, number of threads etc\n",
    "1. Load the data using dataloaders\n",
    "1. Create an instance of the LeNet model\n",
    "1. Specify optimizer to use.\n",
    "1. Set up variables to track loss and accuracy and start training.\n",
    "1. If loss decreases, saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def main(system_configuration=SystemConfiguration(), training_configuration=TrainingConfiguration()):\n",
    "    \n",
    "    # system configuration\n",
    "    setup_system(system_configuration)\n",
    "\n",
    "    # batch size\n",
    "    batch_size_to_set = training_configuration.batch_size\n",
    "    # num_workers\n",
    "    num_workers_to_set = training_configuration.num_workers\n",
    "    # epochs\n",
    "    epoch_num_to_set = training_configuration.epochs_count\n",
    "\n",
    "    # if GPU is available use training config, \n",
    "    # else lowers batch_size, num_workers and epochs count\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda\"\n",
    "    else:\n",
    "        device = \"cpu\"\n",
    "        num_workers_to_set = 2\n",
    "\n",
    "    # data loader\n",
    "    train_loader, test_loader = get_data(\n",
    "        batch_size=training_configuration.batch_size,\n",
    "        data_root=training_configuration.data_root,\n",
    "        num_workers=num_workers_to_set\n",
    "    )\n",
    "    \n",
    "    # Update training configuration\n",
    "    training_configuration = TrainingConfiguration(\n",
    "        device=device,\n",
    "        num_workers=num_workers_to_set\n",
    "    )\n",
    "\n",
    "    # initiate model\n",
    "    model = MyModel()\n",
    "        \n",
    "    # send model to device (GPU/CPU)\n",
    "    model.to(training_configuration.device)\n",
    "\n",
    "    # optimizer\n",
    "    optimizer = optim.SGD(\n",
    "        model.parameters(),\n",
    "        lr=training_configuration.learning_rate\n",
    "    )\n",
    "\n",
    "    best_loss = torch.tensor(np.inf)\n",
    "    best_accuracy = torch.tensor(0)\n",
    "    \n",
    "    # epoch train/test loss\n",
    "    epoch_train_loss = np.array([])\n",
    "    epoch_test_loss = np.array([])\n",
    "    \n",
    "    # epch train/test accuracy\n",
    "    epoch_train_acc = np.array([])\n",
    "    epoch_test_acc = np.array([])\n",
    "    \n",
    "    # trainig time measurement\n",
    "    t_begin = time.time()\n",
    "    for epoch in range(training_configuration.epochs_count):\n",
    "        \n",
    "        train_loss, train_acc = train(training_configuration, model, optimizer, train_loader, epoch)\n",
    "        \n",
    "        epoch_train_loss = np.append(epoch_train_loss, [train_loss])\n",
    "        \n",
    "        epoch_train_acc = np.append(epoch_train_acc, [train_acc])\n",
    "\n",
    "        elapsed_time = time.time() - t_begin\n",
    "        speed_epoch = elapsed_time / (epoch + 1)\n",
    "        speed_batch = speed_epoch / len(train_loader)\n",
    "        eta = speed_epoch * training_configuration.epochs_count - elapsed_time\n",
    "        \n",
    "        print(\n",
    "            \"Elapsed {:.2f}s, {:.2f} s/epoch, {:.2f} s/batch, ets {:.2f}s\".format(\n",
    "                elapsed_time, speed_epoch, speed_batch, eta\n",
    "            )\n",
    "        )\n",
    "\n",
    "        if epoch % training_configuration.test_interval == 0:\n",
    "            current_loss, current_accuracy = validate(training_configuration, model, test_loader)\n",
    "            \n",
    "            epoch_test_loss = np.append(epoch_test_loss, [current_loss])\n",
    "        \n",
    "            epoch_test_acc = np.append(epoch_test_acc, [current_accuracy])\n",
    "            \n",
    "            if current_loss < best_loss:\n",
    "                best_loss = current_loss\n",
    "            \n",
    "            if current_accuracy > best_accuracy:\n",
    "                best_accuracy = current_accuracy\n",
    "                print('Accuracy improved, saving the model.\\n')\n",
    "                save_model(model, device)\n",
    "            \n",
    "                \n",
    "    print(\"Total time: {:.2f}, Best Loss: {:.3f}, Best Accuracy: {:.3f}\".format(time.time() - t_begin, best_loss, \n",
    "                                                                                best_accuracy))\n",
    "    \n",
    "    return model, epoch_train_loss, epoch_train_acc, epoch_test_loss, epoch_test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Accuracy",
     "locked": true,
     "points": "15",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font style=\"color:blue\">Step 11: Start Training</font>\n",
    "This is where you start the training. You may see that the training does not converge or does not give a good accuracy. You need to change \n",
    "- In Step 1: the network architecture and add a few more layers or more nodes to the already existing layers\n",
    "- In Step 5: training parameters such as learning rate or batch_size or epochs so that the network converges or run the network for longer so that it gets more time to fit the data\n",
    "\n",
    "**You need to make sure that the accuracy at the end is at least 75%.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [1600/50000] Loss: 2.135179 Acc: 0.3750\n",
      "Train Epoch: 0 [3200/50000] Loss: 1.770747 Acc: 0.2500\n",
      "Train Epoch: 0 [4800/50000] Loss: 1.452220 Acc: 0.5000\n",
      "Train Epoch: 0 [6400/50000] Loss: 1.582403 Acc: 0.3750\n",
      "Train Epoch: 0 [8000/50000] Loss: 1.914140 Acc: 0.3750\n",
      "Train Epoch: 0 [9600/50000] Loss: 1.399089 Acc: 0.5000\n",
      "Train Epoch: 0 [11200/50000] Loss: 1.470921 Acc: 0.4375\n",
      "Train Epoch: 0 [12800/50000] Loss: 1.428370 Acc: 0.5625\n",
      "Train Epoch: 0 [14400/50000] Loss: 1.599811 Acc: 0.3125\n",
      "Train Epoch: 0 [16000/50000] Loss: 1.124611 Acc: 0.5000\n",
      "Train Epoch: 0 [17600/50000] Loss: 1.839279 Acc: 0.3125\n",
      "Train Epoch: 0 [19200/50000] Loss: 1.330838 Acc: 0.6250\n",
      "Train Epoch: 0 [20800/50000] Loss: 1.557261 Acc: 0.5625\n",
      "Train Epoch: 0 [22400/50000] Loss: 1.686153 Acc: 0.4375\n",
      "Train Epoch: 0 [24000/50000] Loss: 1.536473 Acc: 0.5625\n",
      "Train Epoch: 0 [25600/50000] Loss: 1.451031 Acc: 0.4375\n",
      "Train Epoch: 0 [27200/50000] Loss: 1.127685 Acc: 0.3750\n",
      "Train Epoch: 0 [28800/50000] Loss: 1.262218 Acc: 0.5625\n",
      "Train Epoch: 0 [30400/50000] Loss: 1.228433 Acc: 0.6250\n",
      "Train Epoch: 0 [32000/50000] Loss: 1.002842 Acc: 0.6250\n",
      "Train Epoch: 0 [33600/50000] Loss: 0.644902 Acc: 0.8750\n",
      "Train Epoch: 0 [35200/50000] Loss: 1.168083 Acc: 0.6250\n",
      "Train Epoch: 0 [36800/50000] Loss: 1.109843 Acc: 0.6875\n",
      "Train Epoch: 0 [38400/50000] Loss: 0.595280 Acc: 0.7500\n",
      "Train Epoch: 0 [40000/50000] Loss: 0.647000 Acc: 0.8750\n",
      "Train Epoch: 0 [41600/50000] Loss: 0.613457 Acc: 0.8125\n",
      "Train Epoch: 0 [43200/50000] Loss: 1.179514 Acc: 0.6250\n",
      "Train Epoch: 0 [44800/50000] Loss: 0.921307 Acc: 0.5625\n",
      "Train Epoch: 0 [46400/50000] Loss: 1.096154 Acc: 0.5000\n",
      "Train Epoch: 0 [48000/50000] Loss: 0.741942 Acc: 0.7500\n",
      "Train Epoch: 0 [49600/50000] Loss: 0.819482 Acc: 0.6875\n",
      "Elapsed 290.69s, 290.69 s/epoch, 0.09 s/batch, ets 2616.19s\n",
      "\n",
      "Test set: Average loss: 0.8846, Accuracy: 6858/10000 (69%)\n",
      "\n",
      "Accuracy improved, saving the model.\n",
      "\n",
      "Train Epoch: 1 [1600/50000] Loss: 0.766224 Acc: 0.7500\n",
      "Train Epoch: 1 [3200/50000] Loss: 0.939786 Acc: 0.6875\n",
      "Train Epoch: 1 [4800/50000] Loss: 0.834256 Acc: 0.7500\n",
      "Train Epoch: 1 [6400/50000] Loss: 0.950696 Acc: 0.6875\n",
      "Train Epoch: 1 [8000/50000] Loss: 0.598588 Acc: 0.8125\n",
      "Train Epoch: 1 [9600/50000] Loss: 0.952114 Acc: 0.6250\n",
      "Train Epoch: 1 [11200/50000] Loss: 1.144801 Acc: 0.6250\n",
      "Train Epoch: 1 [12800/50000] Loss: 1.199198 Acc: 0.6250\n",
      "Train Epoch: 1 [14400/50000] Loss: 1.011146 Acc: 0.6875\n",
      "Train Epoch: 1 [16000/50000] Loss: 0.817762 Acc: 0.6875\n",
      "Train Epoch: 1 [17600/50000] Loss: 0.845676 Acc: 0.5000\n",
      "Train Epoch: 1 [19200/50000] Loss: 0.329297 Acc: 0.9375\n",
      "Train Epoch: 1 [20800/50000] Loss: 0.708866 Acc: 0.8125\n",
      "Train Epoch: 1 [22400/50000] Loss: 0.498131 Acc: 0.7500\n",
      "Train Epoch: 1 [24000/50000] Loss: 0.797052 Acc: 0.8125\n",
      "Train Epoch: 1 [25600/50000] Loss: 0.797257 Acc: 0.6875\n",
      "Train Epoch: 1 [27200/50000] Loss: 0.926912 Acc: 0.6875\n",
      "Train Epoch: 1 [28800/50000] Loss: 1.089516 Acc: 0.5625\n",
      "Train Epoch: 1 [30400/50000] Loss: 0.436754 Acc: 0.8125\n",
      "Train Epoch: 1 [32000/50000] Loss: 0.594801 Acc: 0.8125\n",
      "Train Epoch: 1 [33600/50000] Loss: 0.985636 Acc: 0.6875\n",
      "Train Epoch: 1 [35200/50000] Loss: 0.930051 Acc: 0.6250\n",
      "Train Epoch: 1 [36800/50000] Loss: 0.605920 Acc: 0.8125\n",
      "Train Epoch: 1 [38400/50000] Loss: 0.864517 Acc: 0.6875\n",
      "Train Epoch: 1 [40000/50000] Loss: 1.020866 Acc: 0.7500\n",
      "Train Epoch: 1 [41600/50000] Loss: 0.952690 Acc: 0.6875\n",
      "Train Epoch: 1 [43200/50000] Loss: 0.643671 Acc: 0.7500\n",
      "Train Epoch: 1 [44800/50000] Loss: 0.599519 Acc: 0.6875\n",
      "Train Epoch: 1 [46400/50000] Loss: 0.319346 Acc: 0.8750\n",
      "Train Epoch: 1 [48000/50000] Loss: 0.571264 Acc: 0.8750\n",
      "Train Epoch: 1 [49600/50000] Loss: 0.419955 Acc: 0.8125\n",
      "Elapsed 594.26s, 297.13 s/epoch, 0.10 s/batch, ets 2377.02s\n",
      "\n",
      "Test set: Average loss: 0.7168, Accuracy: 7517/10000 (75%)\n",
      "\n",
      "Accuracy improved, saving the model.\n",
      "\n",
      "Train Epoch: 2 [1600/50000] Loss: 0.466661 Acc: 0.9375\n",
      "Train Epoch: 2 [3200/50000] Loss: 0.558891 Acc: 0.8125\n",
      "Train Epoch: 2 [4800/50000] Loss: 0.427597 Acc: 0.8750\n",
      "Train Epoch: 2 [6400/50000] Loss: 0.975202 Acc: 0.6875\n",
      "Train Epoch: 2 [8000/50000] Loss: 0.716439 Acc: 0.6875\n",
      "Train Epoch: 2 [9600/50000] Loss: 0.779653 Acc: 0.7500\n",
      "Train Epoch: 2 [11200/50000] Loss: 0.305324 Acc: 0.9375\n",
      "Train Epoch: 2 [12800/50000] Loss: 0.537916 Acc: 0.8125\n",
      "Train Epoch: 2 [14400/50000] Loss: 0.898033 Acc: 0.6875\n",
      "Train Epoch: 2 [16000/50000] Loss: 0.841589 Acc: 0.6875\n",
      "Train Epoch: 2 [17600/50000] Loss: 0.666323 Acc: 0.7500\n",
      "Train Epoch: 2 [19200/50000] Loss: 0.712747 Acc: 0.6250\n",
      "Train Epoch: 2 [20800/50000] Loss: 0.604870 Acc: 0.8125\n",
      "Train Epoch: 2 [22400/50000] Loss: 0.281674 Acc: 0.8750\n",
      "Train Epoch: 2 [24000/50000] Loss: 0.491182 Acc: 0.8125\n",
      "Train Epoch: 2 [25600/50000] Loss: 0.263333 Acc: 0.9375\n",
      "Train Epoch: 2 [27200/50000] Loss: 0.252725 Acc: 0.8750\n",
      "Train Epoch: 2 [28800/50000] Loss: 0.829440 Acc: 0.7500\n",
      "Train Epoch: 2 [30400/50000] Loss: 0.461596 Acc: 0.8125\n",
      "Train Epoch: 2 [32000/50000] Loss: 0.602696 Acc: 0.7500\n",
      "Train Epoch: 2 [33600/50000] Loss: 0.891816 Acc: 0.8125\n",
      "Train Epoch: 2 [35200/50000] Loss: 0.389618 Acc: 0.8125\n",
      "Train Epoch: 2 [36800/50000] Loss: 0.350692 Acc: 0.9375\n",
      "Train Epoch: 2 [38400/50000] Loss: 0.323875 Acc: 0.8125\n",
      "Train Epoch: 2 [40000/50000] Loss: 0.367342 Acc: 0.9375\n",
      "Train Epoch: 2 [41600/50000] Loss: 0.649312 Acc: 0.7500\n",
      "Train Epoch: 2 [43200/50000] Loss: 0.838476 Acc: 0.7500\n",
      "Train Epoch: 2 [44800/50000] Loss: 0.738796 Acc: 0.7500\n",
      "Train Epoch: 2 [46400/50000] Loss: 0.721368 Acc: 0.8125\n",
      "Train Epoch: 2 [48000/50000] Loss: 0.822945 Acc: 0.8125\n",
      "Train Epoch: 2 [49600/50000] Loss: 0.575910 Acc: 0.8750\n",
      "Elapsed 907.11s, 302.37 s/epoch, 0.10 s/batch, ets 2116.60s\n",
      "\n",
      "Test set: Average loss: 0.6016, Accuracy: 7939/10000 (79%)\n",
      "\n",
      "Accuracy improved, saving the model.\n",
      "\n",
      "Train Epoch: 3 [1600/50000] Loss: 0.470017 Acc: 0.8750\n",
      "Train Epoch: 3 [3200/50000] Loss: 1.022840 Acc: 0.5625\n",
      "Train Epoch: 3 [4800/50000] Loss: 0.490285 Acc: 0.8750\n",
      "Train Epoch: 3 [6400/50000] Loss: 0.847431 Acc: 0.6250\n",
      "Train Epoch: 3 [8000/50000] Loss: 0.558223 Acc: 0.8125\n",
      "Train Epoch: 3 [9600/50000] Loss: 0.613950 Acc: 0.6875\n",
      "Train Epoch: 3 [11200/50000] Loss: 0.742070 Acc: 0.8125\n",
      "Train Epoch: 3 [12800/50000] Loss: 0.704076 Acc: 0.6250\n",
      "Train Epoch: 3 [14400/50000] Loss: 0.335703 Acc: 0.8750\n",
      "Train Epoch: 3 [16000/50000] Loss: 0.398147 Acc: 0.8125\n",
      "Train Epoch: 3 [17600/50000] Loss: 0.370673 Acc: 0.8750\n",
      "Train Epoch: 3 [19200/50000] Loss: 0.425722 Acc: 0.8125\n",
      "Train Epoch: 3 [20800/50000] Loss: 0.287808 Acc: 0.8750\n",
      "Train Epoch: 3 [22400/50000] Loss: 0.476594 Acc: 0.8125\n",
      "Train Epoch: 3 [24000/50000] Loss: 0.564879 Acc: 0.7500\n",
      "Train Epoch: 3 [25600/50000] Loss: 0.328805 Acc: 0.8750\n",
      "Train Epoch: 3 [27200/50000] Loss: 0.809196 Acc: 0.8125\n",
      "Train Epoch: 3 [28800/50000] Loss: 0.376509 Acc: 0.8125\n",
      "Train Epoch: 3 [30400/50000] Loss: 0.738549 Acc: 0.6875\n",
      "Train Epoch: 3 [32000/50000] Loss: 0.324029 Acc: 0.8125\n",
      "Train Epoch: 3 [33600/50000] Loss: 0.590638 Acc: 0.7500\n",
      "Train Epoch: 3 [35200/50000] Loss: 0.363736 Acc: 0.8125\n",
      "Train Epoch: 3 [36800/50000] Loss: 0.428834 Acc: 0.8125\n",
      "Train Epoch: 3 [38400/50000] Loss: 0.556520 Acc: 0.7500\n",
      "Train Epoch: 3 [40000/50000] Loss: 0.337609 Acc: 0.8750\n",
      "Train Epoch: 3 [41600/50000] Loss: 0.429717 Acc: 0.8750\n",
      "Train Epoch: 3 [43200/50000] Loss: 0.232133 Acc: 0.9375\n",
      "Train Epoch: 3 [44800/50000] Loss: 0.390073 Acc: 0.8125\n",
      "Train Epoch: 3 [46400/50000] Loss: 0.322722 Acc: 0.8750\n",
      "Train Epoch: 3 [48000/50000] Loss: 0.269568 Acc: 0.8750\n",
      "Train Epoch: 3 [49600/50000] Loss: 0.591912 Acc: 0.8125\n",
      "Elapsed 1216.11s, 304.03 s/epoch, 0.10 s/batch, ets 1824.16s\n",
      "\n",
      "Test set: Average loss: 0.5891, Accuracy: 8046/10000 (80%)\n",
      "\n",
      "Accuracy improved, saving the model.\n",
      "\n",
      "Train Epoch: 4 [1600/50000] Loss: 0.478734 Acc: 0.8125\n",
      "Train Epoch: 4 [3200/50000] Loss: 0.201071 Acc: 0.9375\n",
      "Train Epoch: 4 [4800/50000] Loss: 0.432878 Acc: 0.7500\n",
      "Train Epoch: 4 [6400/50000] Loss: 0.361996 Acc: 0.8750\n",
      "Train Epoch: 4 [8000/50000] Loss: 0.266315 Acc: 0.9375\n",
      "Train Epoch: 4 [9600/50000] Loss: 0.436979 Acc: 0.8125\n",
      "Train Epoch: 4 [11200/50000] Loss: 0.477327 Acc: 0.8125\n",
      "Train Epoch: 4 [12800/50000] Loss: 0.371160 Acc: 0.9375\n",
      "Train Epoch: 4 [14400/50000] Loss: 0.209897 Acc: 0.9375\n",
      "Train Epoch: 4 [16000/50000] Loss: 0.320717 Acc: 0.8750\n",
      "Train Epoch: 4 [17600/50000] Loss: 0.535518 Acc: 0.6875\n",
      "Train Epoch: 4 [19200/50000] Loss: 0.402624 Acc: 0.9375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 4 [20800/50000] Loss: 0.657153 Acc: 0.8750\n",
      "Train Epoch: 4 [22400/50000] Loss: 0.150763 Acc: 1.0000\n",
      "Train Epoch: 4 [24000/50000] Loss: 0.417259 Acc: 0.8125\n",
      "Train Epoch: 4 [25600/50000] Loss: 0.072787 Acc: 1.0000\n",
      "Train Epoch: 4 [27200/50000] Loss: 0.344661 Acc: 0.8750\n",
      "Train Epoch: 4 [28800/50000] Loss: 0.184612 Acc: 0.9375\n",
      "Train Epoch: 4 [30400/50000] Loss: 0.186227 Acc: 0.8750\n",
      "Train Epoch: 4 [32000/50000] Loss: 0.308448 Acc: 0.8750\n",
      "Train Epoch: 4 [33600/50000] Loss: 0.863504 Acc: 0.6875\n",
      "Train Epoch: 4 [35200/50000] Loss: 0.185021 Acc: 0.8750\n",
      "Train Epoch: 4 [36800/50000] Loss: 0.154900 Acc: 1.0000\n",
      "Train Epoch: 4 [38400/50000] Loss: 0.397015 Acc: 0.8125\n",
      "Train Epoch: 4 [40000/50000] Loss: 0.231642 Acc: 0.8750\n",
      "Train Epoch: 4 [41600/50000] Loss: 0.279673 Acc: 0.8750\n",
      "Train Epoch: 4 [43200/50000] Loss: 0.497440 Acc: 0.8750\n",
      "Train Epoch: 4 [44800/50000] Loss: 0.108376 Acc: 0.9375\n",
      "Train Epoch: 4 [46400/50000] Loss: 0.338213 Acc: 0.9375\n",
      "Train Epoch: 4 [48000/50000] Loss: 0.400103 Acc: 0.9375\n",
      "Train Epoch: 4 [49600/50000] Loss: 0.199147 Acc: 0.9375\n",
      "Elapsed 1527.15s, 305.43 s/epoch, 0.10 s/batch, ets 1527.15s\n",
      "\n",
      "Test set: Average loss: 0.5565, Accuracy: 8102/10000 (81%)\n",
      "\n",
      "Accuracy improved, saving the model.\n",
      "\n",
      "Train Epoch: 5 [1600/50000] Loss: 0.160513 Acc: 0.9375\n",
      "Train Epoch: 5 [3200/50000] Loss: 0.163450 Acc: 1.0000\n",
      "Train Epoch: 5 [4800/50000] Loss: 0.254883 Acc: 0.9375\n",
      "Train Epoch: 5 [6400/50000] Loss: 0.364554 Acc: 0.8125\n",
      "Train Epoch: 5 [8000/50000] Loss: 0.114567 Acc: 1.0000\n",
      "Train Epoch: 5 [9600/50000] Loss: 0.297352 Acc: 0.8750\n",
      "Train Epoch: 5 [11200/50000] Loss: 0.136730 Acc: 0.9375\n",
      "Train Epoch: 5 [12800/50000] Loss: 0.293891 Acc: 0.9375\n",
      "Train Epoch: 5 [14400/50000] Loss: 0.463887 Acc: 0.9375\n",
      "Train Epoch: 5 [16000/50000] Loss: 0.818545 Acc: 0.8750\n",
      "Train Epoch: 5 [17600/50000] Loss: 0.265846 Acc: 0.9375\n",
      "Train Epoch: 5 [19200/50000] Loss: 0.180768 Acc: 0.9375\n",
      "Train Epoch: 5 [20800/50000] Loss: 0.112438 Acc: 0.9375\n",
      "Train Epoch: 5 [22400/50000] Loss: 0.165070 Acc: 0.9375\n",
      "Train Epoch: 5 [24000/50000] Loss: 0.383249 Acc: 0.8750\n",
      "Train Epoch: 5 [25600/50000] Loss: 0.483256 Acc: 0.8125\n",
      "Train Epoch: 5 [27200/50000] Loss: 0.214862 Acc: 0.9375\n",
      "Train Epoch: 5 [28800/50000] Loss: 0.145140 Acc: 0.9375\n",
      "Train Epoch: 5 [30400/50000] Loss: 0.123808 Acc: 1.0000\n",
      "Train Epoch: 5 [32000/50000] Loss: 0.083576 Acc: 1.0000\n",
      "Train Epoch: 5 [33600/50000] Loss: 0.097141 Acc: 0.9375\n",
      "Train Epoch: 5 [35200/50000] Loss: 0.284172 Acc: 0.9375\n",
      "Train Epoch: 5 [36800/50000] Loss: 0.121119 Acc: 0.9375\n",
      "Train Epoch: 5 [38400/50000] Loss: 0.217233 Acc: 0.9375\n",
      "Train Epoch: 5 [40000/50000] Loss: 0.658736 Acc: 0.7500\n",
      "Train Epoch: 5 [41600/50000] Loss: 0.187088 Acc: 0.9375\n",
      "Train Epoch: 5 [43200/50000] Loss: 0.647879 Acc: 0.8125\n",
      "Train Epoch: 5 [44800/50000] Loss: 0.050100 Acc: 1.0000\n",
      "Train Epoch: 5 [46400/50000] Loss: 0.363872 Acc: 0.8750\n",
      "Train Epoch: 5 [48000/50000] Loss: 0.663266 Acc: 0.8750\n",
      "Train Epoch: 5 [49600/50000] Loss: 0.269846 Acc: 0.9375\n",
      "Elapsed 1836.64s, 306.11 s/epoch, 0.10 s/batch, ets 1224.43s\n",
      "\n",
      "Test set: Average loss: 0.5981, Accuracy: 8062/10000 (81%)\n",
      "\n",
      "Train Epoch: 6 [1600/50000] Loss: 0.327690 Acc: 0.8125\n",
      "Train Epoch: 6 [3200/50000] Loss: 0.030083 Acc: 1.0000\n",
      "Train Epoch: 6 [4800/50000] Loss: 0.208793 Acc: 0.9375\n",
      "Train Epoch: 6 [6400/50000] Loss: 0.147411 Acc: 0.9375\n",
      "Train Epoch: 6 [8000/50000] Loss: 0.226760 Acc: 0.8125\n",
      "Train Epoch: 6 [9600/50000] Loss: 0.202710 Acc: 0.9375\n",
      "Train Epoch: 6 [11200/50000] Loss: 0.093592 Acc: 1.0000\n",
      "Train Epoch: 6 [12800/50000] Loss: 0.269132 Acc: 0.9375\n",
      "Train Epoch: 6 [14400/50000] Loss: 0.041736 Acc: 1.0000\n",
      "Train Epoch: 6 [16000/50000] Loss: 0.035922 Acc: 1.0000\n",
      "Train Epoch: 6 [17600/50000] Loss: 0.038464 Acc: 1.0000\n",
      "Train Epoch: 6 [19200/50000] Loss: 0.120939 Acc: 0.9375\n",
      "Train Epoch: 6 [20800/50000] Loss: 0.096560 Acc: 0.9375\n",
      "Train Epoch: 6 [22400/50000] Loss: 0.225941 Acc: 0.9375\n",
      "Train Epoch: 6 [24000/50000] Loss: 0.232205 Acc: 0.9375\n",
      "Train Epoch: 6 [25600/50000] Loss: 0.091334 Acc: 0.9375\n",
      "Train Epoch: 6 [27200/50000] Loss: 0.213249 Acc: 0.8750\n",
      "Train Epoch: 6 [28800/50000] Loss: 0.450071 Acc: 0.8750\n",
      "Train Epoch: 6 [30400/50000] Loss: 0.048603 Acc: 1.0000\n",
      "Train Epoch: 6 [32000/50000] Loss: 0.217426 Acc: 0.9375\n",
      "Train Epoch: 6 [33600/50000] Loss: 0.165690 Acc: 0.9375\n",
      "Train Epoch: 6 [35200/50000] Loss: 0.176725 Acc: 0.9375\n",
      "Train Epoch: 6 [36800/50000] Loss: 0.268648 Acc: 0.8750\n",
      "Train Epoch: 6 [38400/50000] Loss: 0.449496 Acc: 0.8125\n",
      "Train Epoch: 6 [40000/50000] Loss: 0.034461 Acc: 1.0000\n",
      "Train Epoch: 6 [41600/50000] Loss: 0.314950 Acc: 0.8125\n",
      "Train Epoch: 6 [43200/50000] Loss: 0.103654 Acc: 1.0000\n",
      "Train Epoch: 6 [44800/50000] Loss: 0.379863 Acc: 0.8750\n",
      "Train Epoch: 6 [46400/50000] Loss: 0.206789 Acc: 1.0000\n",
      "Train Epoch: 6 [48000/50000] Loss: 0.111728 Acc: 1.0000\n",
      "Train Epoch: 6 [49600/50000] Loss: 0.428328 Acc: 0.9375\n",
      "Elapsed 2204.54s, 314.93 s/epoch, 0.10 s/batch, ets 944.80s\n",
      "\n",
      "Test set: Average loss: 0.5785, Accuracy: 8286/10000 (83%)\n",
      "\n",
      "Accuracy improved, saving the model.\n",
      "\n",
      "Train Epoch: 7 [1600/50000] Loss: 0.052263 Acc: 1.0000\n",
      "Train Epoch: 7 [3200/50000] Loss: 0.293349 Acc: 0.9375\n",
      "Train Epoch: 7 [4800/50000] Loss: 0.013559 Acc: 1.0000\n",
      "Train Epoch: 7 [6400/50000] Loss: 0.070288 Acc: 1.0000\n",
      "Train Epoch: 7 [8000/50000] Loss: 0.022585 Acc: 1.0000\n",
      "Train Epoch: 7 [9600/50000] Loss: 0.005550 Acc: 1.0000\n",
      "Train Epoch: 7 [11200/50000] Loss: 0.089471 Acc: 0.9375\n",
      "Train Epoch: 7 [12800/50000] Loss: 0.061642 Acc: 1.0000\n",
      "Train Epoch: 7 [14400/50000] Loss: 0.176556 Acc: 0.8750\n",
      "Train Epoch: 7 [16000/50000] Loss: 0.022389 Acc: 1.0000\n",
      "Train Epoch: 7 [17600/50000] Loss: 0.069868 Acc: 1.0000\n",
      "Train Epoch: 7 [19200/50000] Loss: 0.108355 Acc: 1.0000\n",
      "Train Epoch: 7 [20800/50000] Loss: 0.103545 Acc: 0.9375\n",
      "Train Epoch: 7 [22400/50000] Loss: 0.162537 Acc: 0.9375\n",
      "Train Epoch: 7 [24000/50000] Loss: 0.144007 Acc: 0.9375\n",
      "Train Epoch: 7 [25600/50000] Loss: 0.078691 Acc: 0.9375\n",
      "Train Epoch: 7 [27200/50000] Loss: 0.142869 Acc: 1.0000\n",
      "Train Epoch: 7 [28800/50000] Loss: 0.146913 Acc: 0.9375\n",
      "Train Epoch: 7 [30400/50000] Loss: 0.185013 Acc: 0.9375\n",
      "Train Epoch: 7 [32000/50000] Loss: 0.023545 Acc: 1.0000\n",
      "Train Epoch: 7 [33600/50000] Loss: 0.004556 Acc: 1.0000\n",
      "Train Epoch: 7 [35200/50000] Loss: 0.376706 Acc: 0.9375\n",
      "Train Epoch: 7 [36800/50000] Loss: 0.042395 Acc: 1.0000\n",
      "Train Epoch: 7 [38400/50000] Loss: 0.371290 Acc: 0.8750\n",
      "Train Epoch: 7 [40000/50000] Loss: 0.127079 Acc: 0.9375\n",
      "Train Epoch: 7 [41600/50000] Loss: 0.021771 Acc: 1.0000\n",
      "Train Epoch: 7 [43200/50000] Loss: 0.238592 Acc: 0.9375\n",
      "Train Epoch: 7 [44800/50000] Loss: 0.178579 Acc: 0.9375\n",
      "Train Epoch: 7 [46400/50000] Loss: 0.188149 Acc: 0.8750\n",
      "Train Epoch: 7 [48000/50000] Loss: 0.124943 Acc: 1.0000\n",
      "Train Epoch: 7 [49600/50000] Loss: 0.650499 Acc: 0.8125\n",
      "Elapsed 2506.42s, 313.30 s/epoch, 0.10 s/batch, ets 626.61s\n",
      "\n",
      "Test set: Average loss: 0.6644, Accuracy: 8193/10000 (82%)\n",
      "\n",
      "Train Epoch: 8 [1600/50000] Loss: 0.161656 Acc: 0.9375\n",
      "Train Epoch: 8 [3200/50000] Loss: 0.084583 Acc: 0.9375\n",
      "Train Epoch: 8 [4800/50000] Loss: 0.018663 Acc: 1.0000\n",
      "Train Epoch: 8 [6400/50000] Loss: 0.070848 Acc: 0.9375\n",
      "Train Epoch: 8 [8000/50000] Loss: 0.034863 Acc: 1.0000\n",
      "Train Epoch: 8 [9600/50000] Loss: 0.013805 Acc: 1.0000\n",
      "Train Epoch: 8 [11200/50000] Loss: 0.136961 Acc: 0.9375\n",
      "Train Epoch: 8 [12800/50000] Loss: 0.034466 Acc: 1.0000\n",
      "Train Epoch: 8 [14400/50000] Loss: 0.008173 Acc: 1.0000\n",
      "Train Epoch: 8 [16000/50000] Loss: 0.112430 Acc: 1.0000\n",
      "Train Epoch: 8 [17600/50000] Loss: 0.004947 Acc: 1.0000\n",
      "Train Epoch: 8 [19200/50000] Loss: 0.057417 Acc: 0.9375\n",
      "Train Epoch: 8 [20800/50000] Loss: 0.092427 Acc: 1.0000\n",
      "Train Epoch: 8 [22400/50000] Loss: 0.085613 Acc: 0.9375\n",
      "Train Epoch: 8 [24000/50000] Loss: 0.009076 Acc: 1.0000\n",
      "Train Epoch: 8 [25600/50000] Loss: 0.046009 Acc: 1.0000\n",
      "Train Epoch: 8 [27200/50000] Loss: 0.009896 Acc: 1.0000\n",
      "Train Epoch: 8 [28800/50000] Loss: 0.028416 Acc: 1.0000\n",
      "Train Epoch: 8 [30400/50000] Loss: 0.277443 Acc: 0.8750\n",
      "Train Epoch: 8 [32000/50000] Loss: 0.138895 Acc: 0.9375\n",
      "Train Epoch: 8 [33600/50000] Loss: 0.002928 Acc: 1.0000\n",
      "Train Epoch: 8 [35200/50000] Loss: 0.002715 Acc: 1.0000\n",
      "Train Epoch: 8 [36800/50000] Loss: 0.033179 Acc: 1.0000\n",
      "Train Epoch: 8 [38400/50000] Loss: 0.100014 Acc: 1.0000\n",
      "Train Epoch: 8 [40000/50000] Loss: 0.107887 Acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 8 [41600/50000] Loss: 0.081803 Acc: 1.0000\n",
      "Train Epoch: 8 [43200/50000] Loss: 0.026423 Acc: 1.0000\n",
      "Train Epoch: 8 [44800/50000] Loss: 0.114036 Acc: 0.9375\n",
      "Train Epoch: 8 [46400/50000] Loss: 0.018553 Acc: 1.0000\n",
      "Train Epoch: 8 [48000/50000] Loss: 0.209663 Acc: 0.9375\n",
      "Train Epoch: 8 [49600/50000] Loss: 0.232879 Acc: 0.8750\n",
      "Elapsed 2839.86s, 315.54 s/epoch, 0.10 s/batch, ets 315.54s\n",
      "\n",
      "Test set: Average loss: 0.8131, Accuracy: 7981/10000 (80%)\n",
      "\n",
      "Train Epoch: 9 [1600/50000] Loss: 0.001450 Acc: 1.0000\n",
      "Train Epoch: 9 [3200/50000] Loss: 0.020169 Acc: 1.0000\n",
      "Train Epoch: 9 [4800/50000] Loss: 0.004724 Acc: 1.0000\n",
      "Train Epoch: 9 [6400/50000] Loss: 0.004881 Acc: 1.0000\n",
      "Train Epoch: 9 [8000/50000] Loss: 0.035274 Acc: 1.0000\n",
      "Train Epoch: 9 [9600/50000] Loss: 0.002254 Acc: 1.0000\n",
      "Train Epoch: 9 [11200/50000] Loss: 0.091483 Acc: 1.0000\n",
      "Train Epoch: 9 [12800/50000] Loss: 0.017980 Acc: 1.0000\n",
      "Train Epoch: 9 [14400/50000] Loss: 0.007223 Acc: 1.0000\n",
      "Train Epoch: 9 [16000/50000] Loss: 0.059982 Acc: 1.0000\n",
      "Train Epoch: 9 [17600/50000] Loss: 0.054953 Acc: 1.0000\n",
      "Train Epoch: 9 [19200/50000] Loss: 0.001690 Acc: 1.0000\n",
      "Train Epoch: 9 [20800/50000] Loss: 0.005732 Acc: 1.0000\n",
      "Train Epoch: 9 [22400/50000] Loss: 0.052837 Acc: 1.0000\n",
      "Train Epoch: 9 [24000/50000] Loss: 0.011127 Acc: 1.0000\n",
      "Train Epoch: 9 [25600/50000] Loss: 0.023917 Acc: 1.0000\n",
      "Train Epoch: 9 [27200/50000] Loss: 0.014482 Acc: 1.0000\n",
      "Train Epoch: 9 [28800/50000] Loss: 0.017929 Acc: 1.0000\n",
      "Train Epoch: 9 [30400/50000] Loss: 0.042908 Acc: 1.0000\n",
      "Train Epoch: 9 [32000/50000] Loss: 0.026846 Acc: 1.0000\n",
      "Train Epoch: 9 [33600/50000] Loss: 0.097145 Acc: 0.9375\n",
      "Train Epoch: 9 [35200/50000] Loss: 0.012359 Acc: 1.0000\n",
      "Train Epoch: 9 [36800/50000] Loss: 0.035286 Acc: 1.0000\n",
      "Train Epoch: 9 [38400/50000] Loss: 0.007757 Acc: 1.0000\n",
      "Train Epoch: 9 [40000/50000] Loss: 0.085628 Acc: 0.9375\n",
      "Train Epoch: 9 [41600/50000] Loss: 0.015958 Acc: 1.0000\n",
      "Train Epoch: 9 [43200/50000] Loss: 0.139195 Acc: 0.9375\n",
      "Train Epoch: 9 [44800/50000] Loss: 0.030866 Acc: 1.0000\n",
      "Train Epoch: 9 [46400/50000] Loss: 0.321520 Acc: 0.9375\n",
      "Train Epoch: 9 [48000/50000] Loss: 0.048253 Acc: 1.0000\n",
      "Train Epoch: 9 [49600/50000] Loss: 0.072702 Acc: 0.9375\n",
      "Elapsed 3145.78s, 314.58 s/epoch, 0.10 s/batch, ets 0.00s\n",
      "\n",
      "Test set: Average loss: 0.7770, Accuracy: 8153/10000 (82%)\n",
      "\n",
      "Total time: 3158.75, Best Loss: 0.557, Best Accuracy: 0.829\n"
     ]
    }
   ],
   "source": [
    "if required_training:\n",
    "    model, epoch_train_loss, epoch_train_acc, epoch_test_loss, epoch_test_acc = main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# <font style=\"color:blue\">12. Plot Loss</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "deletable": false,
    "editable": false,
    "lines_to_next_cell": 2,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot loss\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 6)\n",
    "x = range(len(epoch_train_loss))\n",
    "\n",
    "\n",
    "plt.figure\n",
    "plt.plot(x, epoch_train_loss, color='r', label=\"train loss\")\n",
    "plt.plot(x, epoch_test_loss, color='b', label=\"validation loss\")\n",
    "plt.xlabel('epoch no.')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# <font style=\"color:blue\">13. Plot Accuracy</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Plot loss\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 6)\n",
    "x = range(len(epoch_train_loss))\n",
    "\n",
    "\n",
    "plt.figure\n",
    "plt.plot(x, epoch_train_acc, color='r', label=\"train accuracy\")\n",
    "plt.plot(x, epoch_test_acc, color='b', label=\"validation accuracy\")\n",
    "plt.xlabel('epoch no.')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend(loc='center right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# <font style=\"color:blue\">14. Loading the Model </font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# initialize the model\n",
    "cnn_model = MyModel()\n",
    "\n",
    "models = 'models'\n",
    "\n",
    "model_file_name = 'cifar10_cnn_model.pt'\n",
    "\n",
    "model_path = os.path.join(models, model_file_name)\n",
    "\n",
    "# loading the model and getting model parameters by using load_state_dict\n",
    "cnn_model.load_state_dict(torch.load(model_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# <font style=\"color:blue\">15. Model Prediction</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def prediction(model, train_config, batch_input):\n",
    "    \n",
    "    # send model to cpu/cuda according to your system configuration\n",
    "    model.to(train_config.device)\n",
    "    \n",
    "    # it is important to do model.eval() before prediction\n",
    "    model.eval()\n",
    "\n",
    "    data = batch_input.to(train_config.device)\n",
    "\n",
    "    output = model(data)\n",
    "\n",
    "    # Score to probability using softmax\n",
    "    prob = F.softmax(output, dim=1)\n",
    "\n",
    "    # get the max probability\n",
    "    pred_prob = prob.data.max(dim=1)[0]\n",
    "    \n",
    "    # get the index of the max probability\n",
    "    pred_index = prob.data.max(dim=1)[1]\n",
    "    \n",
    "    return pred_index.cpu().numpy(), pred_prob.cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# <font style=\"color:blue\">16. Perform Inference on sample images </font>\n",
    "\n",
    "For prediction, we need to transform the data in the same way as we have done during training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "lines_to_next_cell": 2,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "batch_size = 5\n",
    "train_config = TrainingConfiguration()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    train_config.device = \"cuda\"\n",
    "else:\n",
    "    train_config.device = \"cpu\"\n",
    "    \n",
    "    \n",
    "\n",
    "# load test data without image transformation\n",
    "test = torch.utils.data.DataLoader(\n",
    "    datasets.CIFAR10(root=train_config.data_root, train=False, download=False, \n",
    "                   transform=transforms.functional.to_tensor),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=1\n",
    "    )\n",
    "\n",
    "try:\n",
    "    mean, std = get_mean_std_train_data(data_root)\n",
    "    assert len(mean) == len(std) == 3\n",
    "except:\n",
    "    mean = (0.5, 0.5, 0.5)\n",
    "    std = (0.5, 0.5, 0.5)\n",
    "\n",
    "# load testdata with image transformation\n",
    "image_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)\n",
    "    ])\n",
    "\n",
    "test_trans = torch.utils.data.DataLoader(\n",
    "    datasets.CIFAR10(root=train_config.data_root, train=False, download=False, transform=image_transforms),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=1\n",
    "    )\n",
    "\n",
    "for data, _ in test_trans:\n",
    "    # pass the loaded model\n",
    "    pred, prob = prediction(cnn_model, train_config, data)\n",
    "    break\n",
    "    \n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (3, 3)\n",
    "for images, label in test:\n",
    "    for i, img in enumerate(images):\n",
    "        img = transforms.functional.to_pil_image(img)\n",
    "        plt.imshow(img)\n",
    "        plt.gca().set_title('Pred: {0}({1:0.2}), Label: {2}'.format(classes[pred[i]], prob[i], classes[label[i]]))\n",
    "        plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font style=\"color:blue\">17. Report your findings</font>\n",
    "- \n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# <font style=\"color:blue\">References</font>\n",
    "\n",
    "1. https://pytorch.org/tutorials/beginner/data_loading_tutorial.html\n",
    "1. https://pytorch.org/tutorials/beginner/saving_loading_models.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7",
   "language": "python",
   "name": "python37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
